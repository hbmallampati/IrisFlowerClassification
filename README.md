## IrisFlowerClassification
#### Description 
The Iris Flower Classification project involved building machine learning models to classify Iris flowers into different species based on the dimensions of their petals and sepals. Three different models were developed and tested: Naive Bayes, K-Means, and Logistic Regression.
1. The Naive Bayes model used probability theory to calculate the likelihood of an Iris flower belonging to a particular species, based on its measurements. 
<p align="center"><img width="900" height="60" alt="Screenshot 2023-04-20 at 2 58 37 PM" src="https://user-images.githubusercontent.com/98439391/233496469-4cfd4a29-11a9-4ce0-83c4-aad683de7b5b.png">
</p>
2. The K-Means model used clustering to group the flowers into different clusters based on their similarities, and then assigned them to a particular species. 
<p align="center"><img width="402" alt="Screenshot 2023-04-20 at 2 51 43 PM" src="https://user-images.githubusercontent.com/98439391/233495470-22b72cf4-a446-489e-952d-3e4214a5a0f5.png">
</p>
3. The Logistic Regression model used regression analysis to estimate the probability of a flower being a certain species, based on its characteristics.
<p align="center"><img width="387" alt="Screenshot 2023-04-20 at 2 55 12 PM" src="https://user-images.githubusercontent.com/98439391/233496037-a2ff73dc-acbf-4cf2-9f9e-a2238eac9bde.png">
</p>
<p align="center"><img width="1091" alt="Screenshot 2023-04-20 at 2 57 26 PM" src="https://user-images.githubusercontent.com/98439391/233496284-d5e19ff3-6339-442a-9bdb-85cb261bd652.png">
</p>
4. A 4-dimensional dataset was analyzed using Principal Component Analysis (PCA) to reduce its dimensionality to 1-dimensional space, while maintaining an accuracy rate of 93%.
<p align="center"><img width="514" alt="Screenshot 2023-04-20 at 2 53 02 PM" src="https://user-images.githubusercontent.com/98439391/233495714-3d2e419a-b5f2-4ef2-bfd9-7fe04c6899f8.png">
</p>
Preprocessed the dataset by performing feature scaling and splitting the data into training and testing sets.
Achieved an average accuracy of 95% on the test set by tuning the hyperparameters of the Naive Bayes model and performing cross-validation. Visualized the dataset using scatter plots and created decision boundaries to visualize the classification results.
